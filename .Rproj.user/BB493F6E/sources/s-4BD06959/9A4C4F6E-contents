---
header-includes: \usetheme{Madrid} \usecolortheme{beaver}
output:
  beamer_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T,
                      message = F,
                      warning = F,
                      comment = "")
```

##

```{r, out.width="100%",fig.align='left',out.height="100%", echo=F}
library(knitr)
include_graphics("images/first_page.PNG")
```

## Session assumption

- Already installed [R](https://cran.r-project.org/) and [Rstdio](https://www.rstudio.com/products/rstudio/download/#download)\vspace{10mm}
- Know how to use R at it's basics (_NOT required_)\vspace{10mm}
- Have atleast handled a messy dataset once before\vspace{10mm}
- Basic understanding of dataset components(variables/rows/cells)\vspace{10mm}


## The tool of trade
This session will focus on learning the basics of data wrangling using R statistical software

**Why R?**

There are other cormercial statistical tools such as STATA, SAS and SPSS that can employed in data management
We chose R over the rest because:-

- Open source (free to use)\newline
- Relates to other languages and systems\newline
- Its flexible, fun and easy to learn\newline
- Outstanding visualization\newline
- Advanced statistical language(a tool for Machine Learning)

Supports user defined extensions (packages) and its cross-platform

# Why should I care about cleaning my data??



## Why should I care about cleaning my data?

- Messy data is everywhere and most real world datasets start off messy in nature
- As data grows bigger, number of things that can go wrong grows in the same magnitude
```{r, out.width="100%",fig.align='left',out.height="80%", echo=F}
library(knitr)
include_graphics("images/data_cycle.PNG")
```


## Preamble

What are some of the issues you get to deal with when it comes to data management??

What are some of the domains for inclusion into your error-checking plan??

- ....
- ....
- ....

## The almost familiar data cycle?
```{r, out.width="100%",fig.align='left',out.height="80%", echo=F}
library(knitr)
include_graphics("images/cleaning_cycle.PNG")
```


## Session Objectives
By the end of the presentation:-

- Get introduced to R for data wrangling\newline
- Be able to read data into R from whichever source it's stored\newline
- Explore your raw data with the aim of deeply understanding it\newline
- Tidy/reshape your data to required format\newline
- Explore toolkit for general data housekeeping in R\newline
- Prepare a dataset for analysis\newline
- Fundamentals of reproducible research

## Follow up plan
In the next couple of minutes, we will explore data munging tasks like:-

- General data validation checks (missing values, outlier values etc.)\vspace{3mm}
- Identifying and removing duplicates\vspace{3mm}
- Manipulating variables\vspace{3mm}
- Creating new variables\vspace{3mm}
- subsetting/filtering data\vspace{3mm}
- Reshaping and Merging datasets

Data cleaning and reshaping is one of the task that we spend much time on while undertaking data management activities

We will introduce a complete toolkit of R packages for cleaning, manipulating, reshaping and visualizing your data

## Getting data into R
Research data can come in different flavours:-

- Flat files (`.xlsx`,`.csv`,`.txt`)\vspace{2mm}
- Data on web-based databases (`REDCap`, `MySQL databases` and `OpenClinica`)\vspace{2mm}
- Data from other statistical softwares (`STATA`, `SAS` and `SPSS`)

We will briefly cover how to read your data into R from the first 2 sources above and begin managing it

```{r flatfiles, eval=F}
library(readxl) # for reading .xlsx files
read_excel()

library(readr) # for reading .csv and .txt files
read_csv() and read_tsv()
```
**NOTE:** Alot of functions are available for reading flat files into R, just `Google` them

## Reading flat files

### Lets see how this works with a practical example


## Connecting R to Web-based databases(1/2)
Special packages and functions are available to help you connect and fetch data stored in your web-based databases from within R software

**Connecting to REDCap**
```{r eval=F}
library(redcapAPI) # load required package
# create a connection
con<-redcapConnection(url='https://redcaplink/api/',
                      token = 'your account token here')
# export data
my_data<-exportRecords(con, fields = NULL, forms = null ,
                       records = NULL, events = NULL , 
                       labels = TRUE, dates = TRUE, 
                       survey = FALSE,factors=F, dag = T,
                       checkboxLabels = TRUE)
?redcapAPI # get more help
```

## Connecting to REDCap

### Lets see how this works with a practical example

## Connecting R to Web-based databases(2/2)

**Connecting to `MySQL` dabases**
```{r eval=F}
library(DBI) # provides the interface
library(RMySQL) # implements the process
# create a connection
con <- dbConnect(MySQL(),
                 host= "hostname",
                 dbname = "databasename",
                 user = "username",
                 password = "password")
# list database tables
dbase_tables <- dbListTables(con)
# export data
my_data <- dbGetQuery(con, "SQL query here")
# close database connection
dbDisconnect(con) # remember to close connection
```

## Connecting to `MySQL` dabases

### Lets see how this works with a practical example


## Cleaning data in R
Steps invloved in cleaning data\vspace{10mm}

- Explore the raw data\vspace{10mm}
- Tidy/reshape your data\vspace{10mm}
- Perform general housekeeping\vspace{10mm}
- Preparing for final analysis\vspace{10mm}

## Cleaning data in R -- Sources of errors

Possible sources of error

- Experimental error\newline
- Data entry error\newline
- Valid measurement (might be) etc.

Identifying errors:-

- **Focus on context** (_"tidy datasets are all alike but every messy dataset is messy in its own way"_ **Hadley Wickham**)\newline

- Possible ranges


## Cleaning data in R -- Exploring raw data
This step is for understanding the structure of your data.
Looking through the data components (what variables, types and scope)

- `class()`
- `dim()`
- `names()`
- `str()` or `glimpse()`
- `summary()`
- `head()`
- `tail()`

You can also visualize data to quickly identify extreme or suspicious values in your data

- histogram
- scatterplots
- boxplots

## Cleaning data in R -- Tidying data
Violations of priniciples of tidy data

- Column headers are values, not variables
- Variables stored in both rows and columns
- Multiple variables are stored in one column

`tidyr()` functions to reshape and restored tidy data

- `gather()`
- `spread()`
- `separate()`
- `unite()`

`gather()` and `spread()` outputs gives rise to most commonly reffered types of datasets

- `wide datasets` _more columns than rows_
- `long datasets` _more rows than columns_

## Data Cleaning in R -- General Housekeeping
We will explore a sample dataset using `dplyr` functions among others

**dplyr functions**

- `select()`   : Subset columns
- `filter()`   : Subset rows
- `arrange()`  : Reorders rows
- `mutate()`   : Add columns to existing data
- `summarise()`: Summarizing data set

**additional functions**

- `summary()` : printing general summary
- `is.na()`   : checking for missing values
- `merge()`   : to merge 2 datasets

## Data Warehousing

### Lets see how this works with a practical example


## Cleaning data in R -- Prepare for data analysis
Properly licensing your data for an analysis

Type conversion at its basic ( _putting variables into their required formats_ )

- **character**
- integer
- logical
- **factor**
- string manipulation

Its extremely important to know how to convert your variables from one type to another just incase you require it

- `as.*` family of functions for type conversion
- dealing with missing values `na.omit()` and `complete.cases()`
- outliers/obvious errors -- `histograms and boxplots`



## Exporting datasets/saving files (Output)
R allows you to save or export datasets from the workspace into `.csv` or `tab delimeted`\newline

```{r, eval=F, echo=TRUE}
write.csv(dataset_name, "dest_folder/preferred_name.csv")
```


You can also save an entire workspace and load it later to an R session like this\newline
```{r eval=F, echo=T}
save(list = ls(),file = "pref_name.RDA") # save datasets in workspace

load("pref_name.RDA") # load back items into workspace
```



## Reports authoring, visualization and reproducible research
Two most powerful tools for report authoring, visualization and process automation

- [**Rmarkdown**](https://rmarkdown.rstudio.com/lesson-1.html) is file format for making dynamic documents with R\newline

- [**Shiny**](https://www.rstudio.com/products/shiny/) is an open source R package that provides an elegant and powerful web framework for building web applications using R


**NOTE:** R Shiny and creating reports dashboards is beyond the scope of this workshop

## R shiny dashboard workflow
How does it work?

```{r out.width="50%",fig.align='center',out.height="80%", echo=F}
library(knitr)
include_graphics("images/flow_diagram.png")
```


## R Shiny framework(1/2)
```{r, out.width="100%",fig.align='left',out.height="80%", echo=F}
library(knitr)
include_graphics("images/anatomy.PNG")
```

## R Shiny framework(2/2)
```{r, out.width="100%",fig.align='left',out.height="80%", echo=F}
library(knitr)
include_graphics("images/implement_app.PNG")
```
A built example is [**CHAIN Network Reports Dashboard**](https://reports.chainnetwork.org/)

## Version control scripts and projects within RStudio
Rstudio IDE supports version control systems such as `Git` and `SVN`.
Enables vesrion control data analysis/management codes as well documents withing the R project.

```{r why R, out.width="100%",fig.align='centre',out.height="60%", echo=F}
library(knitr)
include_graphics("images/terminal_window.png")
```

##

```{r, out.width="100%",fig.align='left',out.height="100%", echo=F}
library(knitr)
include_graphics("images/last_page.PNG")
```




